# -*- coding: utf-8 -*-
"""Kiruthiga M_Credit card fraud detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RgME6uoSucGfhVkcL0W5xFzwlW5VEz-8
"""

# =====================================================
# CREDIT CARD FRAUD DETECTION - ANN & Autoencoder
# =====================================================

# 1️⃣ Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns

# 2️⃣ Load Dataset
df = pd.read_csv("creditcard.csv")
print("Dataset shape:", df.shape)
print(df.head())
print("\nClass distribution:\n", df['Class'].value_counts())

# 3️⃣ Handle missing values & convert target to int
df.dropna(subset=['Class'], inplace=True)
df['Class'] = df['Class'].astype(int)

# 4️⃣ Features & Target
X = df.drop("Class", axis=1).values
y = df["Class"].values

# 5️⃣ Scale Features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 6️⃣ Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# 7️⃣ Handle Imbalance using SMOTE
sm = SMOTE(random_state=42)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)
print("\nBefore SMOTE:", np.bincount(y_train))
print("After SMOTE:", np.bincount(y_train_res))

# 8️⃣ Build ANN Model
ann_model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.4),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])
ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
ann_model.summary()

# 9️⃣ Train ANN
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
history = ann_model.fit(
    X_train_res, y_train_res,
    epochs=20,
    batch_size=2048,
    validation_split=0.1,
    callbacks=[early_stop],
    verbose=2
)

# 1️⃣0️⃣ Plot Training & Validation Loss
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("ANN Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# 1️⃣1️⃣ Evaluate ANN on Test Set
y_pred_prob = ann_model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int)

print("\nConfusion Matrix (ANN):")
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

print("\nClassification Report (ANN):")
print(classification_report(y_test, y_pred))

roc_auc = roc_auc_score(y_test, y_pred_prob)
print(f"ROC-AUC Score (ANN): {roc_auc:.4f}")

# Optional: ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
plt.figure(figsize=(6,6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.4f})')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - ANN')
plt.legend()
plt.show()

# =====================================================
# 1️⃣2️⃣ Autoencoder for Anomaly Detection
# =====================================================
# Use only normal transactions for training
X_train_ae = X_train[y_train == 0]

input_dim = X_train_ae.shape[1]
input_layer = Input(shape=(input_dim,))
encoded = Dense(32, activation='relu')(input_layer)
encoded = Dense(16, activation='relu')(encoded)
decoded = Dense(32, activation='relu')(encoded)
decoded = Dense(input_dim, activation='linear')(decoded)

autoencoder = Model(inputs=input_layer, outputs=decoded)
autoencoder.compile(optimizer='adam', loss='mse')
autoencoder.summary()

# Train Autoencoder
history_ae = autoencoder.fit(
    X_train_ae, X_train_ae,
    epochs=20,
    batch_size=2048,
    validation_split=0.1,
    verbose=2
)

# Reconstruction error on test set
X_test_pred = autoencoder.predict(X_test)
reconstruction_error = np.mean(np.square(X_test - X_test_pred), axis=1)

# Detect anomalies (fraud) using threshold
threshold = np.mean(reconstruction_error) + 3*np.std(reconstruction_error)
y_pred_ae = (reconstruction_error > threshold).astype(int)

# Evaluate Autoencoder
print("\nConfusion Matrix (Autoencoder):")
cm_ae = confusion_matrix(y_test, y_pred_ae)
sns.heatmap(cm_ae, annot=True, fmt='d', cmap='Oranges')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

print("\nClassification Report (Autoencoder):")
print(classification_report(y_test, y_pred_ae))

roc_auc_ae = roc_auc_score(y_test, reconstruction_error)
print(f"ROC-AUC Score (Autoencoder): {roc_auc_ae:.4f}")

# Optional: ROC Curve for Autoencoder
fpr_ae, tpr_ae, thresholds_ae = roc_curve(y_test, reconstruction_error)
plt.figure(figsize=(6,6))
plt.plot(fpr_ae, tpr_ae, label=f'ROC curve (AUC = {roc_auc_ae:.4f})')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Autoencoder')
plt.legend()
plt.show()